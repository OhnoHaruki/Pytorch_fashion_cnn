{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionMNISTを使用したCNNの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブライのインんストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロードと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像のデータの水増し\n",
    "affine = transforms.RandomAffine([-15,15],scale=(0.7,1.3))#回転とリサイズの定義\n",
    "horizonal_flip = transforms.RandomHorizontalFlip(p = 0.5) #左右反転させる確率\n",
    "vertical_flip = transforms.RandomVerticalFlip(p = 0.5) #上下反転させる確率\n",
    "normalize = transforms.Normalize((0.0),(1.0)) #平均値を０に、標準偏差を1に変更\n",
    "totensor = transforms.ToTensor()#テンソル化\n",
    "\n",
    "fashion_mnist_data = torchvision.datasets.FashionMNIST(#fashion_mnistのデータを取ってくる\n",
    "    './fashion-mnist',train=True,download=True,transform=torchvision.transforms.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "transform_train = transforms.Compose([affine,horizonal_flip,vertical_flip,totensor,normalize])#学習用データの前処理\n",
    "transform_test = transforms.Compose([totensor,normalize])#テスト用データの前処理\n",
    "\n",
    "#今回の使用するデータであるfashion_mnistのダウンロード\n",
    "fashion_mnist_data_train = torchvision.datasets.FashionMNIST(\n",
    "    './fashion-mnist',train=True,download=True,transform=transform_train)\n",
    "fashion_mnist_data_test = torchvision.datasets.FashionMNIST(\n",
    "    './fashion-mnist',train=False,download=True,transform=transform_test)\n",
    "\n",
    "#DataLoaderの設定\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(fashion_mnist_data_train,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(fashion_mnist_data_test,batch_size=len(fashion_mnist_data_test),shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),#畳み込みレイヤーとして2D畳み込みを適用する\n",
    "            nn.ELU(),#活性化関数としてELUを適用する\n",
    "            nn.MaxPool2d(kernel_size=2),# プーリングレイヤーとして2D最大プーリングを適用する\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),#入力テンソルの一部をランダムにゼロに設定する\n",
    "            nn.Linear(64 * 7 * 7, 128),#受信データび線形変換を適用する\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1),#出力層での活性化関数いついてlogsoftmaxを適用する\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)#全ての次元を平坦化する\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "net = Net()\n",
    "net.cuda() #GPU対応\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの訓練(学習)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#損失関数(交差エントロピー関数)\n",
    "loss_fnc = nn.CrossEntropyLoss()\n",
    "\n",
    "#最適化アルゴリズム(adam)\n",
    "optimizer = optim.AdamW(net.parameters())\n",
    "\n",
    "#損失ログ\n",
    "record_loss_train = []\n",
    "record_loss_test = []\n",
    "\n",
    "#学習\n",
    "x_test, t_test = iter(test_loader).next()#test_loaderからデータを取り出す\n",
    "x_test, t_test = x_test.cuda(), t_test.cuda()#gpuに送信\n",
    "for i in range(20):#20エポック学習\n",
    "    net.train()#訓練モード\n",
    "    loss_train = 0\n",
    "    for j, (x,t) in enumerate(train_loader):#ミニバッチ(x,t)を取り出す\n",
    "        x, t = x.cuda(), t.cuda()#GPU対応\n",
    "        y = net(x)\n",
    "        loss = loss_fnc(y, t)#損失関数\n",
    "        loss_train += loss.item()#lossからtensorの要素を所得\n",
    "        optimizer.zero_grad()#勾配の初期化(backeardする前に行う)\n",
    "        loss.backward()#逆伝播を行う\n",
    "        optimizer.step()#重みの更新\n",
    "\n",
    "    loss_train /= j + 1\n",
    "    record_loss_train.append(loss_train)\n",
    "\n",
    "    net.eval()#評価モード\n",
    "    y_test = net(x_test)\n",
    "    loss_test = loss_fnc(y_test, t_test).item()\n",
    "    record_loss_test.append(loss_test)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        print(\"Epoch:\", i, \"Loss_Train:\", loss_train, \"Loss_Test:\", loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差の推移\n",
    "訓練データ、テストデータで誤差の推移をグラフ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n",
    "plt.plot(range(len(record_loss_test)), record_loss_test, label = \"Test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正解率の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.eval() #評価モード\n",
    "for i, (x,t) in enumerate(test_loader):\n",
    "    x, t = x.cuda(), t.cuda()#GPU対応\n",
    "    y = net(x)\n",
    "    correct += (y.argmax(1) == t).sum().item()\n",
    "    total += len(x)\n",
    "print(\"正解率:\", str(correct/total*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),\"drive/My Drive/Python_learning/fashion_mnist_cnn/model_cnn_fashin_mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loaded = Net()\n",
    "net_loaded.load_state_dict(torch.load(\"drive/My Drive/Python_learning/fashion_mnist_cnn/model_cnn_fashin_mnist.pth\",map_location=torch.device(\"cpu\")))#cpu対応\n",
    "net_loaded.eval() #評価モード"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
